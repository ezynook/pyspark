{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02965f-1c7d-4773-8818-b91e18f35513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0838a17-89a8-4e38-b9c0-7044a2f664ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Variable\n",
    "SCHEMA=\"main\"\n",
    "TABLE=\"survival\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6cddf-bbe6-4148-891c-a68fb4b8ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HADOOP_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "os.environ['HADOOP_USER_NAME']='hive'\n",
    "os.environ['PYSPARK_PYTHON'] ='/root/anaconda3/bin/python'\n",
    "conf = pyspark.SparkConf().setAll([\n",
    "     ('spark.driver.maxResultSize', '0'),\n",
    "     ('spark.driver.memory', '2g'),\n",
    "     ('spark.sql.repl.eagerEval.enabled','true'),\n",
    "     ('hive.strict.managed.tables','false'),\n",
    "     ('hive.metastore.uris', 'thrift://hive-metastore:9083'),\n",
    "     ('metastore.client.capability.check','false')\n",
    "    ])\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"street\") \\\n",
    "        .config(conf=conf) \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603390a3-1d85-4255-8542-de71e093248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"https://vincentarelbundock.github.io/Rdatasets/csv/{TABLE}/nafld2.csv\")\n",
    "df = df.rename(columns={\"Unnamed: 0\": \"idx\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de08b6e-1100-441f-a33c-3313ba76e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(df)\n",
    "df2 = df2.sort([\"idx\"],ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedbb9cd-394b-4946-ab77-72b0ed948e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spark.sql(f\"SHOW TABLES IN {SCHEMA}\").filter(f\"tableName == '{TABLE}'\").count() > 0:\n",
    "    repartitioned = df2.repartition('test')\n",
    "    repartitioned.write \\\n",
    "\t\t.mode('append') \\\n",
    "\t\t.partitionBy('test') \\\n",
    "\t\t.bucketBy(5, 'value') \\\n",
    "\t\t.saveAsTable(f'{SCHEMA}.{TABLE}')\n",
    "else:\n",
    "    df2.write \\\n",
    "\t\t.mode('overwrite') \\\n",
    "\t\t.partitionBy('test') \\\n",
    "\t\t.bucketBy(5, 'value') \\\n",
    "\t\t.saveAsTable(f'{SCHEMA}.{TABLE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc303376-4ccb-4113-b472-14fee2c02de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
