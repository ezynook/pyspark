{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c58ed-5680-4110-827e-e141f4fe2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e76aff-0b01-46b8-840f-9e299788a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "update_dt = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "today = now.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa6331-ee10-4adf-87b2-0370e9320edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZABBIX_API_URL = \"http://192.168.10.109/zabbix/api_jsonrpc.php\"\n",
    "UNAME = \"Admin\"\n",
    "PWORD = \"zabbix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac3012-9064-4e06-975e-5704e866702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HADOOP_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "os.environ['HADOOP_USER_NAME']='hive'\n",
    "os.environ['PYSPARK_PYTHON'] ='/root/anaconda3/bin/python'\n",
    "conf = pyspark.SparkConf().setAll([\n",
    "     ('spark.driver.maxResultSize', '0'),\n",
    "     ('spark.driver.memory', '2g'),\n",
    "     ('spark.sql.repl.eagerEval.enabled','true'),\n",
    "     (\"spark.driver.allowMultipleContexts\", \"true\"),\n",
    "     ('hive.strict.managed.tables','false'),\n",
    "     ('hive.metastore.uris', 'thrift://hive-metastore:9083'),\n",
    "     ('metastore.client.capability.check','false')\n",
    "    ])\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"Zabbix\") \\\n",
    "        .config(conf=conf) \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e0c25-82a9-4dfc-ae2a-f74dfc3f8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Auth():\n",
    "    r = requests.post(ZABBIX_API_URL,\n",
    "                  json={\n",
    "                      \"jsonrpc\": \"2.0\",\n",
    "                      \"method\": \"user.login\",\n",
    "                      \"params\": {\n",
    "                          \"user\": UNAME,\n",
    "                          \"password\": PWORD},\n",
    "                      \"id\": 1\n",
    "                  })\n",
    "    AUTHTOKEN = r.json()[\"result\"]\n",
    "    return AUTHTOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce49d6-51b8-4517-aa21-7b8fa5a892ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item():\n",
    "    r = requests.post(ZABBIX_API_URL, json={\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"method\": \"item.get\",\n",
    "        \"params\": {\n",
    "            \"output\": \"extend\",\n",
    "        },\n",
    "            \"auth\": Auth(),\n",
    "            \"id\": 1\n",
    "    })\n",
    "    data = []\n",
    "    for row in r.json()['result']:\n",
    "        data.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa6f226-d30c-4300-b17e-4acc32e2b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "readfile = pd.DataFrame(get_item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0d9d4-f708-4d67-9452-4b1c7f1c7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "readfile = readfile.replace(\"\\r\\n\",'', regex=True)\n",
    "readfile = readfile.replace(\"\\[]\",'', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d051bfa-25c8-4a4e-bed6-6abf38e616a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "readfile.to_csv('/tmp/get_item.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf01ee-0427-40f2-aedd-ddef2435147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('/tmp/get_item.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53481284-4e0e-438f-b5ad-b598673906f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spark.sql(\"SHOW TABLES IN main\").filter(\"tableName == 'zbx_item'\").count() > 0:\n",
    "    # df.write \\\n",
    "    # .mode(\"append\") \\\n",
    "    # .partitionBy(\"hostid\") \\\n",
    "    # .saveAsTable(\"main.zbx_item\")\n",
    "    print(\"Table is Exists\")\n",
    "else:\n",
    "    df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"hostid\") \\\n",
    "    .saveAsTable(\"main.zbx_item\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
