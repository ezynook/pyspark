{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a8bf8e1-06e4-4a87-b079-a9deb1526fa1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Open Session Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d564e-bf16-4ff0-a653-41a706f2be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f56e2-933a-444d-bb9f-e76e58f609c4",
   "metadata": {},
   "source": [
    "## Hive Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b2bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['HADOOP_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['JAVA_HOME'] = '/usr/local/jdk8u222-b10'\n",
    "os.environ['HADOOP_USER_NAME']='hive'\n",
    "os.environ['PYSPARK_PYTHON'] ='/HDFS01/anaconda3/envs/main/bin/python'\n",
    "conf = pyspark.SparkConf().setAll([\n",
    "     ('spark.driver.maxResultSize', '0'),\n",
    "     ('spark.driver.memory', '2g'),\n",
    "     (\"spark.driver.allowMultipleContexts\", \"true\"),\n",
    "     ('spark.sql.repl.eagerEval.enabled','true'),\n",
    "     ('hive.strict.managed.tables','false'),\n",
    "     ('hive.metastore.uris', 'thrift://nn01.bigdata:9083'),\n",
    "     ('metastore.client.capability.check','false')\n",
    "    ])\n",
    "sparkHive = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"testreplace\") \\\n",
    "        .config(conf=conf) \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5126ca0c-333c-4b35-a0f7-3f0072909eb3",
   "metadata": {},
   "source": [
    "## อ่านข้อมูลจาก Hive และส่งออกไปยัง CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f3628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hiveDF = sparkHive.read.table('pyspark.affairs')\n",
    "hiveDF.write.mode('overwrite').option(\"header\",\"true\").csv(\"file:///tmp/affairs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62438a67-f73d-407a-8bda-35252219bafc",
   "metadata": {},
   "source": [
    "## ปิด Session Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87425bc3-ef02-470e-80a5-f32a87a2c6bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparkHive.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d0067-dccf-48dc-ae2f-f640e091f3d8",
   "metadata": {},
   "source": [
    "## Open Session MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363f1d4-62b9-4df3-b4c0-baf8117fcded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparkMysql = SparkSession.builder \\\n",
    "           .appName('MySQL') \\\n",
    "           .config(\"spark.jars\", \"./jars/mysql-connector-java-8.0.32.jar\") \\\n",
    "           .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7bd52-c6e6-450b-acdb-acaafd3bfe2a",
   "metadata": {},
   "source": [
    "## Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de5fa5-dab5-47f8-bd7e-587f8d225e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = StructType([\n",
    "    StructField(\"affairs\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"age\", StringType(), True),\n",
    "    StructField(\"yearsmarried\", StringType(), True),\n",
    "    StructField(\"children\", StringType(), True),\n",
    "    StructField(\"religiousness\", StringType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"rating\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b993296c-a049-4675-98b7-7fac8e765baa",
   "metadata": {},
   "source": [
    "## อ่านข้อมูจาก CSV (ใน Session Hive) และเขียนลง MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa0ce1-9348-4fad-92a9-d277442085a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sparkMysql.read.csv(\"file:///tmp/affairs.csv\", schema=cols)\n",
    "df.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .mode('overwrite') \\\n",
    "  .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://192.168.10.22:3306/test\") \\\n",
    "  .option(\"dbtable\", \"affairs\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\", \"P@ssw0rd\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503d005-5cd2-4512-9cb3-0b8d9377c433",
   "metadata": {},
   "source": [
    "## ปิด Session MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f223f9-fd4a-4147-bdab-4fde96e57d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparkMysql.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
