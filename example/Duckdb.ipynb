{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49456e17-2f3d-48ba-8d5d-81492ad3742e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://duckdb.org/images/DuckDB_Logo_dl.png\" width=\"150\">\n",
    "\n",
    "__Package Install__\n",
    "\n",
    "```pip install duckdb==0.8.1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de4ceb4-30ee-4bc9-a461-94f534544b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94251a1-0954-493f-8c30-1ad2c0fe4fb4",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Connect DuckDB\n",
    "* Connect in Memory ```duckdb.connect(\"\")```\n",
    "* Connect to files ```duckdb.connect(\"db.db\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5768efa-0d21-41ee-b6f0-8774a785d105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mydb = duckdb.connect(database=':memory:', read_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5199fa-b6b5-442d-9b2d-3bb89bf2d77e",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Read CSV to Pandas\n",
    "\n",
    "---\n",
    "\n",
    "__Multiple files__\n",
    "```sql\n",
    "-- read all files with a name ending in \".csv\" in the folder \"dir\"\n",
    "SELECT * FROM 'dir/*.csv';\n",
    "-- read all files with a name ending in \".csv\", two directories deep\n",
    "SELECT * FROM '*/*/*.csv';\n",
    "-- read all files with a name ending in \".csv\", at any depth in the folder \"dir\"\n",
    "SELECT * FROM 'dir/**/*.csv';\n",
    "-- read the CSV files 'flights1.csv' and 'flights2.csv'\n",
    "SELECT * FROM read_csv_auto(['flights1.csv', 'flights2.csv'])\n",
    "-- read the CSV files 'flights1.csv' and 'flights2.csv', unifying schemas by name and outputting a `filename` column\n",
    "SELECT * FROM read_csv_auto(['flights1.csv', 'flights2.csv'], union_by_name=True, filename=True)\n",
    "```\n",
    "__Parquet files__\n",
    "```sql\n",
    "-- read all files that match the glob pattern\n",
    "SELECT * FROM 'test/*.parquet';\n",
    "-- read 3 parquet files and treat them as a single table\n",
    "SELECT * FROM read_parquet(['file1.parquet', 'file2.parquet', 'file3.parquet']);\n",
    "-- Read all parquet files from 2 specific folders\n",
    "SELECT * FROM read_parquet(['folder1/*.parquet','folder2/*.parquet']);\n",
    "-- read all parquet files that match the glob pattern at any depth\n",
    "SELECT * FROM read_parquet('dir/**/*.parquet');\n",
    "\n",
    "```\n",
    "### Read From URL run this Command \n",
    "```py\n",
    "mydb.sql(\"INSTALL httpfs;\")\n",
    "mydb.sql(\"LOAD httpfs;\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ac8a6-9a27-4bec-9e9c-41ed07f318b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mydata = duckdb.execute(\"\"\"SELECT * FROM read_csv_auto('engineer.csv');\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500fe50f-ecf6-4f43-ab1d-8d2a7e5aba29",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Read Parquet\n",
    "---\n",
    "__Multiple files__\n",
    "```sql\n",
    "-- read data from a hive partitioned data set\n",
    "SELECT * FROM parquet_scan('orders/*/*/*.parquet', hive_partitioning=1);\n",
    "-- write a table to a hive partitioned data set\n",
    "COPY orders TO 'orders' (FORMAT PARQUET, PARTITION_BY (year, month));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c1acd-80e6-4dd0-9d18-37da477350f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = duckdb.execute(\"\"\"SELECT * FROM parquet_scan('engineer.parquet');\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f499558a-9087-41df-bb03-faf5973293c9",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Copy Export Data to Another files\n",
    "\n",
    "---\n",
    "__Copy__\n",
    "```sql\n",
    "-- read a CSV file into the lineitem table - using auto-detected options\n",
    "COPY lineitem FROM 'lineitem.csv' (AUTO_DETECT TRUE);\n",
    "-- read a parquet file into the lineitem table\n",
    "COPY lineitem FROM 'lineitem.pq' (FORMAT PARQUET);\n",
    "-- read a json file into the lineitem table - using auto-detected options\n",
    "COPY lineitem FROM 'lineitem.json' (FORMAT JSON, AUTO_DETECT TRUE);\n",
    "\n",
    "-- write a table to a CSV file\n",
    "COPY lineitem TO 'lineitem.csv' (FORMAT CSV, DELIMITER '|', HEADER);\n",
    "-- write the result of a query to a Parquet file\n",
    "COPY (SELECT l_orderkey, l_partkey FROM lineitem) TO 'lineitem.parquet' (COMPRESSION ZSTD);\n",
    "```\n",
    "__Copy From__\n",
    "```sql\n",
    "-- Copy the contents of a comma-separated file 'test.csv' without a header into the table 'test'\n",
    "COPY test FROM 'test.csv';\n",
    "-- Copy the contents of a comma-separated file with a header into the 'category' table\n",
    "COPY category FROM 'categories.csv' ( HEADER );\n",
    "-- Copy the contents of 'lineitem.tbl' into the 'lineitem' table, where the contents are delimited by a pipe character ('|')\n",
    "COPY lineitem FROM 'lineitem.tbl' ( DELIMITER '|' );\n",
    "-- Copy the contents of 'lineitem.tbl' into the 'lineitem' table, where the delimiter, quote character, and presence of a header are automatically detected\n",
    "COPY lineitem FROM 'lineitem.tbl' ( AUTO_DETECT TRUE );\n",
    "-- Read the contents of a comma-separated file 'names.csv' into the 'name' column of the 'category' table. Any other columns of this table are filled with their default value.\n",
    "COPY category(name) FROM 'names.csv';\n",
    "-- Read the contents of a parquet file 'lineitem.parquet' into the lineitem table\n",
    "COPY lineitem FROM 'lineitem.parquet' ( FORMAT PARQUET );\n",
    "-- Read the contents of a newline-delimited json file 'lineitem.ndjson' into the lineitem table\n",
    "COPY lineitem FROM 'lineitem.ndjson' ( FORMAT JSON );\n",
    "-- Read the contents of a json file 'lineitem.json' into the lineitem table\n",
    "COPY lineitem FROM 'lineitem.json' ( FORMAT JSON, ARRAY TRUE );\n",
    "```\n",
    "__Copy to__\n",
    "```sql\n",
    "-- Copy the contents of the 'lineitem' table to the file 'lineitem.tbl', where the columns are delimited by a pipe character ('|'), including a header line.\n",
    "COPY lineitem TO 'lineitem.tbl' ( DELIMITER '|', HEADER );\n",
    "-- Copy the l_orderkey column of the 'lineitem' table to the file 'orderkey.tbl'\n",
    "COPY lineitem(l_orderkey) TO 'orderkey.tbl' ( DELIMITER '|' );\n",
    "-- Copy the result of a query to the file 'query.csv', including a header with column names\n",
    "COPY (SELECT 42 AS a, 'hello' AS b) TO 'query.csv' WITH (HEADER 1, DELIMITER ',');\n",
    "-- Copy the result of a query to the Parquet file 'query.parquet'\n",
    "COPY (SELECT 42 AS a, 'hello' AS b) TO 'query.parquet' (FORMAT PARQUET);\n",
    "-- Copy the result of a query to the newline-delimited JSON file 'query.ndjson'\n",
    "COPY (SELECT 42 AS a, 'hello' AS b) TO 'query.ndjson' (FORMAT JSON);\n",
    "-- Copy the result of a query to the JSON file 'query.json'\n",
    "COPY (SELECT 42 AS a, 'hello' AS b) TO 'query.json' (FORMAT JSON, ARRAY TRUE);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c575d-3cb3-4601-a108-67ba86248f10",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ SQL to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21187379-e84a-48f3-bc9c-70cd293969c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pandas.DataFrame.from_dict({'a': [42]})\n",
    "results = duckdb.sql(\"SELECT * FROM my_df\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5613a885-e48a-4649-b6b2-c34c8c796402",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Import From Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51dfb3-0791-4248-b593-bdd96507ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pandas.DataFrame.from_dict({'a': [42]})\n",
    "duckdb.sql(\"CREATE TABLE my_table AS SELECT * FROM my_df\")\n",
    "duckdb.sql(\"INSERT INTO my_table SELECT * FROM my_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3858c0df-3558-4167-9f42-97e9ff2bfb60",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Create Table\n",
    "```sql\n",
    "CREATE TABLE weather (\n",
    "    city           VARCHAR,\n",
    "    temp_lo        INTEGER, -- minimum temperature on a day\n",
    "    temp_hi        INTEGER, -- maximum temperature on a day\n",
    "    prcp           REAL,\n",
    "    date           DATE\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb1ef89-4c4b-416f-b839-47a2696dcc17",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Export MemoryDB to FileDB\n",
    "---\n",
    "__More command__\n",
    "```sql\n",
    "-- export the table contents with the given options\n",
    "EXPORT DATABASE 'target_directory' (FORMAT CSV, DELIMITER '|');\n",
    "-- export the table contents as parquet\n",
    "EXPORT DATABASE 'target_directory' (FORMAT PARQUET);\n",
    "-- export as parquet, compressed with ZSTD, with a row_group_size of 100000\n",
    "EXPORT DATABASE 'target_directory' (FORMAT PARQUET, COMPRESSION ZSTD, ROW_GROUP_SIZE 100000);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea77b0e-914f-43f4-a45e-43aef55564bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "duckdb.execute(\"EXPORT DATABASE './nook.db';\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae9ed1-56ff-4bfe-9f31-b55491cf18e1",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Import FileDB to MemoryDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987a0f4-072e-4616-ad17-bc68d1281262",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.execute(\"IMPORT DATABASE 'target_directory'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8ca8a-c6da-484f-aa06-732bca7e0115",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Create view to ETL or Cleansing\n",
    "---\n",
    "__More command__\n",
    "\n",
    "```sql\n",
    "-- create a simple view\n",
    "CREATE VIEW v1 AS SELECT * FROM tbl;\n",
    "-- create a view or replace it if a view with that name already exists\n",
    "CREATE OR REPLACE VIEW v1 AS SELECT 42;\n",
    "-- create a view and replace the column names\n",
    "CREATE VIEW v1(a) AS SELECT 42;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c304fd4-ffa2-4d79-9177-9255b8ba2aa6",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Rebuild DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e0674-2a43-4408-83a2-b256dcfb411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.execute(\"VACUUM ANALYZE;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf8c72-4405-4183-9728-ff1dbbcabeed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
