‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ SQL ‡∏ö‡∏ô PySpark ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ `SparkSession` ‡πÅ‡∏•‡∏∞ `DataFrame` ‡∏ã‡∏∂‡πà‡∏á PySpark ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö SQL query ‡∏ú‡πà‡∏≤‡∏ô `sql()` method ‡πÅ‡∏•‡∏∞ `createOrReplaceTempView()` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á temporary table

* * *

## üîπ **1. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô PySpark SQL**

PySpark SQL ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ `SparkSession` ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

### ‚úÖ **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PySpark (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)**

```bash
pip install pyspark
```

### ‚úÖ **‡∏™‡∏£‡πâ‡∏≤‡∏á SparkSession**

```python
from pyspark.sql import SparkSession

# ‡∏™‡∏£‡πâ‡∏≤‡∏á SparkSession
spark = SparkSession.builder.appName("PySparkSQLExample").getOrCreate()
```

* * *

## üîπ **2. ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡πÅ‡∏•‡∏∞ Query ‡∏î‡πâ‡∏ß‡∏¢ SQL**

‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ `createOrReplaceTempView()` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏à‡∏≤‡∏Å DataFrame

### ‚úÖ **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ SQL Query**

```python
from pyspark.sql import Row

# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
data = [
    Row(id=1, name="Alice", age=25, salary=3000),
    Row(id=2, name="Bob", age=30, salary=4000),
    Row(id=3, name="Charlie", age=28, salary=3500)
]

# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame
df = spark.createDataFrame(data)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Temporary Table
df.createOrReplaceTempView("employees")

# ‡πÉ‡∏ä‡πâ SQL Query
result = spark.sql("SELECT * FROM employees WHERE age > 26")
result.show()
```

### üîç **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**

```
+---+-------+---+------+
| id|   name|age|salary|
+---+-------+---+------+
|  2|    Bob| 30|  4000|
|  3|Charlie| 28|  3500|
+---+-------+---+------+
```

* * *

## üîπ **3. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ SQL Aggregation Functions**

PySpark SQL ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡πÄ‡∏ä‡πà‡∏ô `SUM()`, `AVG()`, `COUNT()`, `MAX()`, `MIN()`

### ‚úÖ **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 2: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢**

```python
avg_salary = spark.sql("SELECT AVG(salary) as avg_salary FROM employees")
avg_salary.show()
```

### üîç **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**

```
+----------+
|avg_salary|
+----------+
|    3500.0|
+----------+
```

* * *

## üîπ **4. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ GROUP BY ‡πÅ‡∏•‡∏∞ ORDER BY**

PySpark SQL ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö `GROUP BY` ‡πÅ‡∏•‡∏∞ `ORDER BY` ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô SQL ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

### ‚úÖ **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3: ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö**

```python
grouped = spark.sql("""
    SELECT age, COUNT(*) as count 
    FROM employees 
    GROUP BY age 
    ORDER BY age DESC
""")
grouped.show()
```

### üîç **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**

```
+---+-----+
|age|count|
+---+-----+
| 30|    1|
| 28|    1|
| 25|    1|
+---+-----+
```

* * *

## üîπ **5. ‡∏Å‡∏≤‡∏£ JOIN ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô PySpark SQL**

‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ SQL ‡πÄ‡∏û‡∏∑‡πà‡∏≠ JOIN ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á DataFrame ‡πÑ‡∏î‡πâ

### ‚úÖ **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 4: INNER JOIN**

```python
# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô
job_data = [
    Row(id=1, job="Engineer"),
    Row(id=2, job="Manager"),
    Row(id=3, job="Analyst")
]

# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame
job_df = spark.createDataFrame(job_data)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Temporary Table
job_df.createOrReplaceTempView("jobs")

# ‡∏ó‡∏≥ INNER JOIN
join_result = spark.sql("""
    SELECT employees.id, employees.name, employees.age, jobs.job
    FROM employees
    INNER JOIN jobs ON employees.id = jobs.id
""")
join_result.show()
```

### üîç **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**

```
+---+-------+---+--------+
| id|   name|age|     job|
+---+-------+---+--------+
|  1|  Alice| 25|Engineer|
|  2|    Bob| 30| Manager|
|  3|Charlie| 28| Analyst|
+---+-------+---+--------+
```

* * *

## üîπ **6. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ CASE WHEN (‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç IF-ELSE)**

PySpark SQL ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ `CASE WHEN` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç

### ‚úÖ **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 5: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô**

```python
salary_level = spark.sql("""
    SELECT name, salary,
    CASE 
        WHEN salary >= 4000 THEN 'High'
        WHEN salary >= 3000 THEN 'Medium'
        ELSE 'Low'
    END AS salary_level
    FROM employees
""")
salary_level.show()
```

### üîç **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**

```
+-------+------+------------+
|   name|salary|salary_level|
+-------+------+------------+
|  Alice|  3000|     Medium|
|    Bob|  4000|       High|
|Charlie|  3500|     Medium|
+-------+------+------------+
```

* * *

## üîπ **7. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Window Functions (‡πÄ‡∏ä‡πà‡∏ô RANK, DENSE_RANK)**

Window Functions ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö (`RANK()`)

### ‚úÖ **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 6: ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô**

```python
rank_salary = spark.sql("""
    SELECT name, salary, 
    RANK() OVER (ORDER BY salary DESC) as rank
    FROM employees
""")
rank_salary.show()
```

### üîç **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**

```
+-------+------+----+
|   name|salary|rank|
+-------+------+----+
|    Bob|  4000|   1|
|Charlie|  3500|   2|
|  Alice|  3000|   3|
+-------+------+----+
```

* * *

## üîπ **8. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ UDF (User Defined Function) ‡πÉ‡∏ô SQL**

‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Python ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÉ‡∏ô SQL ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ `udf()`

### ‚úÖ **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 7: ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà**

```python
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Python
def to_upper(name):
    return name.upper()

# ‡∏™‡∏£‡πâ‡∏≤‡∏á UDF
upper_udf = udf(to_upper, StringType())

# ‡πÉ‡∏ä‡πâ UDF ‡πÉ‡∏ô SQL
df.withColumn("name_upper", upper_udf(df.name)).show()
```

### üîç **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**

```
+---+-------+---+------+----------+
| id|   name|age|salary|name_upper|
+---+-------+---+------+----------+
|  1|  Alice| 25|  3000|    ALICE|
|  2|    Bob| 30|  4000|      BOB|
|  3|Charlie| 28|  3500|  CHARLIE|
+---+-------+---+------+----------+
```

* * *

## üî• **‡∏™‡∏£‡∏∏‡∏õ**

‚úÖ PySpark SQL ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô SQL ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ  
‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `AVG()`, `SUM()`, `GROUP BY`, `ORDER BY`, `JOIN`  
‚úÖ ‡πÉ‡∏ä‡πâ `createOrReplaceTempView()` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß  
‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Window Functions (`RANK()`, `DENSE_RANK()`)  
‚úÖ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á UDF ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô SQL Query ‡πÑ‡∏î‡πâ